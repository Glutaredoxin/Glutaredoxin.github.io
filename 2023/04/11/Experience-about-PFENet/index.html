<!DOCTYPE html>
<html>
    <!-- Head -->
    <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="author" content="Glutaredoxin">
    <meta name="description" itemprop="description" content="">
    <meta name="keywords" content="">

    <!-- Page Title -->
    
        <title>Experience about PFENet | Glutaredoxin&#39;log</title>
    
    <link rel="icon" href="/img/strawberry.png">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
    <link href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">
    
    <script src="//cdn.bootcss.com/prettify/r298/prettify.min.js" type="text/javascript"></script>
    <link rel="stylesheet" href="/css/google-prettify-monokai.css" type="text/css">
    
    
<script src="/js/script.js"></script>

    
<link rel="stylesheet" href="/css/style.css">

    
    <style>
        .deactiveColor{
            color: #37474f;
        }
        .activeColor{
            color: #006064;
        }
        a:hover{
            color: #006064;
        }
        .header-btn{
            color: #37474f;
        }
        
        .post-content img{
            margin: 50px auto;
        }
        
    </style>
<meta name="generator" content="Hexo 7.3.0"></head>
    <body>
        <div class="container">

            <!-- Top Anchor -->
            <div id="top"></div>

            <!-- Header -->
            <header class="header-wrapper">
    <div class="header-title-wrapper">
        <!-- Page Title -->
        <p class="header-title">
             
                
                    Experience about PFENet
                
            
        </p>  
    </div>    

    
        <!-- Division Line -->
        <div class="division"></div> 
    
    
    <div class="header-detail">
        <!-- Header Button -->
        <div class="header-btn-wrapper">
            
                <span>
                    <a class="home-btn header-btn" href="/" title="homepage"><i class="fa fa-home"></i></a>
                </span>

                
                    <span>
                        <a class="catalog-btn header-btn"><i class="fa fa-list-ul"></i></a>
                    </span>
                
            
        </div>
    </div>
</header>

            <!-- Main -->
            <main>
                <article class="post-wrapper">
    

    
        <!-- Article Catalog -->
        <div class="catalog-dropdown col-xs-12 col-sm-12">
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%98%BFExperience-about-PFENet"><span class="toc-number">1.</span> <span class="toc-text">üòøExperience about PFENet</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8D%8Esetting"><span class="toc-number">1.1.</span> <span class="toc-text">üçésetting:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8D%89details"><span class="toc-number">1.2.</span> <span class="toc-text">üçâdetails:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A5%95core-code"><span class="toc-number">1.3.</span> <span class="toc-text">ü•ïcore code:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#prior-generation"><span class="toc-number">1.3.1.</span> <span class="toc-text">prior generation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FEM"><span class="toc-number">1.3.2.</span> <span class="toc-text">FEM</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A5%9Dproblem"><span class="toc-number">1.4.</span> <span class="toc-text">ü•ùproblem:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%9D%93PIL-and-cv2"><span class="toc-number">1.4.1.</span> <span class="toc-text">‚ùìPIL and cv2</span></a></li></ol></li></ol></li></ol>
        </div>
    

    
        <!--For now, Lightbox Only Show in Post Layout -->
        

        
        
            <!-- Article Img Lightbox -->
            <div class="gallery">
    
    
    <div class="lightbox">
        <!-- Close Button -->
        <span class="close-gallery">&times;</span>
        
        <!-- Photo -->
        <img class="gallery-photo">
    </div>
</div>
        
    

    

    <!-- Article Content -->
    <div class="post-content">
        <h1 id="üòøExperience-about-PFENet"><a href="#üòøExperience-about-PFENet" class="headerlink" title="üòøExperience about PFENet"></a>üòøExperience about PFENet</h1><h2 id="üçésetting"><a href="#üçésetting" class="headerlink" title="üçésetting:"></a>üçésetting:</h2><table>
<thead>
<tr>
<th></th>
<th>PASCAL</th>
<th>COCO</th>
</tr>
</thead>
<tbody><tr>
<td>imagesize</td>
<td>(473,473)</td>
<td>(641, 641)</td>
</tr>
<tr>
<td>ppm_scale</td>
<td>[1.0, 0.5, 0.25, 0.125]</td>
<td>[60, 30, 15,8]</td>
</tr>
<tr>
<td>lr</td>
<td>0.0025</td>
<td>0.02</td>
</tr>
</tbody></table>
<h2 id="üçâdetails"><a href="#üçâdetails" class="headerlink" title="üçâdetails:"></a>üçâdetails:</h2><ol>
<li> can resize the origin size of image when evaluating
</li>
<li>train episodes: about 5000
</li>
<li>test episodes: about 1200 and need episode alone
</li>
</ol>

<h2 id="ü•ïcore-code"><a href="#ü•ïcore-code" class="headerlink" title="ü•ïcore code:"></a>ü•ïcore code:</h2><h3 id="prior-generation"><a href="#prior-generation" class="headerlink" title="prior generation"></a>prior generation</h3><p>High-level features:</p>
<p>for each shot od support sets:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">similarity = torch.bmm(tmp_supp, tmp_query)/(torch.bmm(tmp_supp_norm, tmp_query_norm) + cosine_eps)</span><br><span class="line"></span><br><span class="line">similarity = similarity.max(1)[0].view(bsize, sp_sz*sp_sz)   </span><br><span class="line"></span><br><span class="line">similarity = (similarity - similarity.min(1)[0].unsqueeze(1))/(similarity.max(1)[0].unsqueeze(1) - similarity.min(1)[0].unsqueeze(1) + cosine_eps)</span><br><span class="line"></span><br><span class="line">corr_query = similarity.view(bsize, 1, sp_sz, sp_sz)</span><br><span class="line"></span><br><span class="line">corr_query = F.interpolate(corr_query, size=(query_feat_3.size()[2], query_feat_3.size()[3]), mode=&#x27;bilinear&#x27;, align_corners=True)</span><br></pre></td></tr></table></figure>

<h3 id="FEM"><a href="#FEM" class="headerlink" title="FEM"></a>FEM</h3><p>middle-level features:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># 1√ó1 conv -&gt; 256dim</span><br><span class="line">supp_feat = self.down_supp(supp_feat)</span><br><span class="line">query_feat = self.down_query(query_feat)</span><br><span class="line"></span><br><span class="line"># FEM module</span><br><span class="line">for idx, tmp_bin in enumerate(self.pyramid_bins):</span><br><span class="line">    if tmp_bin &lt;= 1.0:</span><br><span class="line">        bin = int(query_feat.shape[2] * tmp_bin)</span><br><span class="line">        query_feat_bin = nn.AdaptiveAvgPool2d(bin)(query_feat)</span><br><span class="line">    else:</span><br><span class="line">        bin = tmp_bin</span><br><span class="line">        query_feat_bin = self.avgpool_list[idx](query_feat)</span><br><span class="line">    supp_feat_bin = supp_feat.expand(-1, -1, bin, bin)</span><br><span class="line">    corr_mask_bin = F.interpolate(corr_query_mask, size=(bin, bin), mode=&#x27;bilinear&#x27;, align_corners=True)</span><br><span class="line">    merge_feat_bin = torch.cat([query_feat_bin, supp_feat_bin, corr_mask_bin], 1)</span><br><span class="line">    merge_feat_bin = self.init_merge[idx](merge_feat_bin)</span><br><span class="line"></span><br><span class="line">    if idx &gt;= 1:</span><br><span class="line">        pre_feat_bin = pyramid_feat_list[idx-1].clone()</span><br><span class="line">        pre_feat_bin = F.interpolate(pre_feat_bin, size=(bin, bin), mode=&#x27;bilinear&#x27;, align_corners=True)</span><br><span class="line">        rec_feat_bin = torch.cat([merge_feat_bin, pre_feat_bin], 1)</span><br><span class="line">        merge_feat_bin = self.alpha_conv[idx-1](rec_feat_bin) + merge_feat_bin  </span><br><span class="line"></span><br><span class="line">    merge_feat_bin = self.beta_conv[idx](merge_feat_bin) + merge_feat_bin   </span><br><span class="line">    inner_out_bin = self.inner_cls[idx](merge_feat_bin)</span><br><span class="line">    merge_feat_bin = F.interpolate(merge_feat_bin, size=(query_feat.size(2), query_feat.size(3)), mode=&#x27;bilinear&#x27;, align_corners=True)</span><br><span class="line">    pyramid_feat_list.append(merge_feat_bin)</span><br><span class="line">    out_list.append(inner_out_bin)</span><br><span class="line">                 </span><br><span class="line">query_feat = torch.cat(pyramid_feat_list, 1)</span><br><span class="line">query_feat = self.res1(query_feat)</span><br><span class="line">query_feat = self.res2(query_feat) + query_feat           </span><br><span class="line">out = self.cls(query_feat)</span><br></pre></td></tr></table></figure>

<h2 id="ü•ùproblem"><a href="#ü•ùproblem" class="headerlink" title="ü•ùproblem:"></a>ü•ùproblem:</h2><ol>
<li>
I do not figure out the detailed infrastructure configuration, like image size, ppm_scale for different datasets.
</li>
<li>
The performance is good to test dataloader and model build by myself separately. However, not together...üí¢
</li>
<li>
update<font color=Blue>April, 12</font>, dataloader is wrong! repairing... 
<ul>
<li>
Numpy.ndarray or list or ..., will be the tensor through the DATALOADER.
</li>
<li>
In image transform, PIL is .size[0] is width, .size[1] is height. However, when transform to tensor, .shape[0] is height, .shape[1] is width. It is reverse.
</li>
</ul>
</li>
</ol>

<p>‚ùótransform:</p>
<p><img src="https://raw.githubusercontent.com/Glutaredoxin/image/main/image_test.png" alt="FEM_standard_image"><br><img src="https://raw.githubusercontent.com/Glutaredoxin/image/main/pascal_image_test.png" alt="self_image"></p>
<p><img src="https://raw.githubusercontent.com/Glutaredoxin/image/main/label_test_2.png" alt="FEM_standard_label"><br><img src="https://raw.githubusercontent.com/Glutaredoxin/image/main/pascal_label_test.png" alt="self_label"></p>
<p>We can see, color, size, crop and padding is wrong! origin image do not change scale of image, however, our image change the scale of image.</p>
<p>So, we need to change the transform.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">import collections</span><br><span class="line">import numbers</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">from PIL import Image</span><br><span class="line">from scipy import ndimage</span><br><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">import torchvision.transforms.functional as tr_F</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">class Resize(object):</span><br><span class="line">    def __init__(self, size):</span><br><span class="line">        self.size = size</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, label = sample[&#x27;image&#x27;], sample[&#x27;semantic_mask&#x27;]</span><br><span class="line"></span><br><span class="line">        def find_new_hw(ori_h, ori_w, test_size):</span><br><span class="line">            # print(ori_h)</span><br><span class="line">            # print(type(ori_h))</span><br><span class="line">            if ori_h &gt;= ori_w:</span><br><span class="line">                ratio = test_size * 1 / ori_h</span><br><span class="line">                new_h = test_size</span><br><span class="line">                new_w = int(ori_w * ratio)</span><br><span class="line">            elif ori_w &gt; ori_h:</span><br><span class="line">                ratio = test_size * 1 / ori_w</span><br><span class="line">                new_h = int(ori_h * ratio)</span><br><span class="line">                new_w = test_size</span><br><span class="line"></span><br><span class="line">            if new_h % 8 != 0:</span><br><span class="line">                new_h = (int(new_h / 8)) * 8</span><br><span class="line">            else:</span><br><span class="line">                new_h = new_h</span><br><span class="line">            if new_w % 8 != 0:</span><br><span class="line">                new_w = (int(new_w / 8)) * 8</span><br><span class="line">            else:</span><br><span class="line">                new_w = new_w</span><br><span class="line">            return new_h, new_w</span><br><span class="line"></span><br><span class="line">        new_h, new_w = find_new_hw(image.size[0], image.size[1], self.size)</span><br><span class="line">        img = tr_F.resize(image, [int(new_w), int(new_h)], interpolation=Image.NEAREST)</span><br><span class="line">        back_crop = np.zeros((self.size, self.size, 3), dtype=np.uint8)</span><br><span class="line">        back_crop[:new_w, :new_h, :] = img</span><br><span class="line">        image = back_crop</span><br><span class="line"></span><br><span class="line">        new_h, new_w = find_new_hw(label.size[0], label.size[1], self.size)</span><br><span class="line">        label = tr_F.resize(label, [int(new_w), int(new_h)], interpolation=Image.NEAREST)</span><br><span class="line">        back_crop_s_mask = np.ones((self.size, self.size)) * 255</span><br><span class="line">        back_crop_s_mask[:new_w, :new_h] = label</span><br><span class="line">        label = back_crop_s_mask</span><br><span class="line"></span><br><span class="line">        sample[&#x27;image&#x27;] = image</span><br><span class="line">        sample[&#x27;semantic_mask&#x27;] = label</span><br><span class="line"></span><br><span class="line">        return sample</span><br><span class="line"></span><br><span class="line">class ToTensorNormalize(object):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Convert images/masks to torch.Tensor</span><br><span class="line">    Scale images&#x27; pixel values to [0-1] and normalize with predefined statistics</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        img, label = sample[&#x27;image&#x27;], sample[&#x27;semantic_mask&#x27;]</span><br><span class="line">        img = tr_F.to_tensor(img)</span><br><span class="line">        img = tr_F.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])</span><br><span class="line">        if isinstance(label, dict):</span><br><span class="line">            label = &#123;catId: torch.Tensor(np.array(x)).long()</span><br><span class="line">                     for catId, x in label.items()&#125;</span><br><span class="line">        else:</span><br><span class="line">            label = torch.Tensor(np.array(label)).long()</span><br><span class="line">        sample[&#x27;image&#x27;] = img</span><br><span class="line">        sample[&#x27;semantic_mask&#x27;] = label</span><br><span class="line"></span><br><span class="line">        return sample</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class RandScale(object):</span><br><span class="line">    def __init__(self, scale, aspect_ratio=None):</span><br><span class="line">        assert (isinstance(scale, collections.Iterable) and len(scale) == 2)</span><br><span class="line">        if isinstance(scale, collections.Iterable) and len(scale) == 2 \</span><br><span class="line">                and isinstance(scale[0], numbers.Number) and isinstance(scale[1], numbers.Number) \</span><br><span class="line">                and 0 &lt; scale[0] &lt; scale[1]:</span><br><span class="line">            self.scale = scale</span><br><span class="line">        else:</span><br><span class="line">            raise (RuntimeError(&quot;segtransform.RandScale() scale param error.\n&quot;))</span><br><span class="line">        if aspect_ratio is None:</span><br><span class="line">            self.aspect_ratio = aspect_ratio</span><br><span class="line">        elif isinstance(aspect_ratio, collections.Iterable) and len(aspect_ratio) == 2 \</span><br><span class="line">                and isinstance(aspect_ratio[0], numbers.Number) and isinstance(aspect_ratio[1], numbers.Number) \</span><br><span class="line">                and 0 &lt; aspect_ratio[0] &lt; aspect_ratio[1]:</span><br><span class="line">            self.aspect_ratio = aspect_ratio</span><br><span class="line">        else:</span><br><span class="line">            raise (RuntimeError(&quot;segtransform.RandScale() aspect_ratio param error.\n&quot;))</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, label = sample[&#x27;image&#x27;], sample[&#x27;semantic_mask&#x27;]</span><br><span class="line">        temp_scale = self.scale[0] + (self.scale[1] - self.scale[0]) * random.random()</span><br><span class="line">        temp_aspect_ratio = 1.0</span><br><span class="line">        if self.aspect_ratio is not None:</span><br><span class="line">            temp_aspect_ratio = self.aspect_ratio[0] + (self.aspect_ratio[1] - self.aspect_ratio[0]) * random.random()</span><br><span class="line">            temp_aspect_ratio = math.sqrt(temp_aspect_ratio)</span><br><span class="line"></span><br><span class="line">        scale_factor_x = temp_scale * temp_aspect_ratio</span><br><span class="line">        scale_factor_y = temp_scale / temp_aspect_ratio</span><br><span class="line">        image = tr_F.resize(image, [int(scale_factor_x * image.size[1]), int(scale_factor_y * image.size[0])],</span><br><span class="line">                            interpolation=Image.BILINEAR)</span><br><span class="line">        label = tr_F.resize(label, [int(scale_factor_x * label.size[1]), int(scale_factor_y * label.size[0])],</span><br><span class="line">                            interpolation=Image.NEAREST)</span><br><span class="line"></span><br><span class="line">        sample[&#x27;image&#x27;] = image</span><br><span class="line">        sample[&#x27;semantic_mask&#x27;] = label</span><br><span class="line">        return sample</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class RandRotate(object):</span><br><span class="line">    # Randomly rotate image &amp; label with rotate factor in [rotate_min, rotate_max]</span><br><span class="line">    def __init__(self, rotate, padding, ignore_label=255, p=0.5):</span><br><span class="line">        assert (isinstance(rotate, collections.Iterable) and len(rotate) == 2)</span><br><span class="line">        if isinstance(rotate[0], numbers.Number) and isinstance(rotate[1], numbers.Number) and rotate[0] &lt; rotate[1]:</span><br><span class="line">            self.rotate = rotate</span><br><span class="line">        else:</span><br><span class="line">            raise (RuntimeError(&quot;segtransform.RandRotate() scale param error.\n&quot;))</span><br><span class="line">        assert padding is not None</span><br><span class="line">        assert isinstance(padding, list) and len(padding) == 3</span><br><span class="line">        if all(isinstance(i, numbers.Number) for i in padding):</span><br><span class="line">            self.padding = padding</span><br><span class="line">        else:</span><br><span class="line">            raise (RuntimeError(&quot;padding in RandRotate() should be a number list\n&quot;))</span><br><span class="line">        assert isinstance(ignore_label, int)</span><br><span class="line">        self.ignore_label = ignore_label</span><br><span class="line">        self.p = p</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, label = sample[&#x27;image&#x27;], sample[&#x27;semantic_mask&#x27;]</span><br><span class="line">        if random.random() &lt; self.p:</span><br><span class="line">            angle = self.rotate[0] + (self.rotate[1] - self.rotate[0]) * random.random()</span><br><span class="line">            h, w = label.size[-2:]</span><br><span class="line">            image = tr_F.rotate(image, angle=angle)</span><br><span class="line">            label = tr_F.rotate(label, angle=angle)</span><br><span class="line"></span><br><span class="line">        sample[&#x27;image&#x27;] = image</span><br><span class="line">        sample[&#x27;semantic_mask&#x27;] = label</span><br><span class="line">        return sample</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class RandomGaussianBlur(object):</span><br><span class="line">    def __init__(self, radius=5):</span><br><span class="line">        self.radius = radius</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, label = sample[&#x27;image&#x27;], sample[&#x27;semantic_mask&#x27;]</span><br><span class="line">        if random.random() &lt; 0.5:</span><br><span class="line">            image = tr_F.gaussian_blur(image, [self.radius, self.radius], 3)</span><br><span class="line">        sample[&#x27;image&#x27;] = image</span><br><span class="line">        return sample</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class RandomHorizontalFlip(object):</span><br><span class="line">    def __init__(self, p=0.5):</span><br><span class="line">        self.p = p</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, label = sample[&#x27;image&#x27;], sample[&#x27;semantic_mask&#x27;]</span><br><span class="line">        if random.random() &lt; self.p:</span><br><span class="line">            image = tr_F.hflip(image)</span><br><span class="line">            label = tr_F.hflip(label)</span><br><span class="line"></span><br><span class="line">        sample[&#x27;image&#x27;] = image</span><br><span class="line">        sample[&#x27;semantic_mask&#x27;] = label</span><br><span class="line">        return sample</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class RGB2BGR(object):</span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, label = sample[&#x27;image&#x27;], sample[&#x27;semantic_mask&#x27;]</span><br><span class="line">        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)</span><br><span class="line">        sample[&#x27;image&#x27;] = image</span><br><span class="line">        return sample</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Crop(object):</span><br><span class="line">    def __init__(self, size, crop_type=&#x27;center&#x27;, padding=None, ignore_label=255):</span><br><span class="line">        self.size = size</span><br><span class="line">        if isinstance(size, int):</span><br><span class="line">            self.crop_h = size</span><br><span class="line">            self.crop_w = size</span><br><span class="line">        elif isinstance(size, collections.Iterable) and len(size) == 2 \</span><br><span class="line">                and isinstance(size[0], int) and isinstance(size[1], int) \</span><br><span class="line">                and size[0] &gt; 0 and size[1] &gt; 0:</span><br><span class="line">            self.crop_h = size[0]</span><br><span class="line">            self.crop_w = size[1]</span><br><span class="line">        else:</span><br><span class="line">            raise (RuntimeError(&quot;crop size error.\n&quot;))</span><br><span class="line">        if crop_type == &#x27;center&#x27; or crop_type == &#x27;rand&#x27;:</span><br><span class="line">            self.crop_type = crop_type</span><br><span class="line">        else:</span><br><span class="line">            raise (RuntimeError(&quot;crop type error: rand | center\n&quot;))</span><br><span class="line">        if padding is None:</span><br><span class="line">            self.padding = padding</span><br><span class="line">        elif isinstance(padding, list):</span><br><span class="line">            if all(isinstance(i, numbers.Number) for i in padding):</span><br><span class="line">                self.padding = padding</span><br><span class="line">            else:</span><br><span class="line">                raise (RuntimeError(&quot;padding in Crop() should be a number list\n&quot;))</span><br><span class="line">            if len(padding) != 3:</span><br><span class="line">                raise (RuntimeError(&quot;padding channel is not equal with 3\n&quot;))</span><br><span class="line">        else:</span><br><span class="line">            raise (RuntimeError(&quot;padding in Crop() should be a number list\n&quot;))</span><br><span class="line">        if isinstance(ignore_label, int):</span><br><span class="line">            self.ignore_label = ignore_label</span><br><span class="line">        else:</span><br><span class="line">            raise (RuntimeError(&quot;ignore_label should be an integer number\n&quot;))</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, label = sample[&#x27;image&#x27;], sample[&#x27;semantic_mask&#x27;]</span><br><span class="line"></span><br><span class="line">        self.padding = [int(temp) for temp in self.padding]</span><br><span class="line">        self.padding = tuple(self.padding)</span><br><span class="line">        h = label.size[0]</span><br><span class="line">        w = label.size[1]</span><br><span class="line"></span><br><span class="line">        pad_h = max(self.crop_h - h, 0)</span><br><span class="line">        pad_w = max(self.crop_w - w, 0)</span><br><span class="line">        pad_h_half = int(pad_h / 2)</span><br><span class="line">        pad_w_half = int(pad_w / 2)</span><br><span class="line">        pad_h = int(pad_h)</span><br><span class="line">        pad_w = int(pad_w)</span><br><span class="line"></span><br><span class="line">        if pad_h &gt; 0 or pad_w &gt; 0:</span><br><span class="line">            if self.padding is None:</span><br><span class="line">                raise (RuntimeError(&quot;segtransform.Crop() need padding while padding argument is None\n&quot;))</span><br><span class="line">            image = tr_F.pad(image, [int(pad_h - pad_h_half), int(pad_w - pad_w_half), pad_h_half, pad_w_half],</span><br><span class="line">                             fill=self.padding, padding_mode=&#x27;constant&#x27;)</span><br><span class="line">            # IMAGE = tr.RandomCrop((473, 473), padding = [pad_h_half, pad_h - pad_h_half, pad_w_half, pad_w - pad_w_half], pad_if_needed = False, fill = self.padding, padding_mode = &#x27;constant&#x27; )</span><br><span class="line">            label = tr_F.pad(label, [int(pad_h - pad_h_half), int(pad_w - pad_w_half), pad_h_half, pad_w_half],</span><br><span class="line">                             fill=255, padding_mode=&#x27;constant&#x27;)</span><br><span class="line">        h = label.size[0]</span><br><span class="line">        w = label.size[1]</span><br><span class="line">        image = np.array(image)</span><br><span class="line">        label = np.array(label)</span><br><span class="line">        raw_label = label</span><br><span class="line">        raw_image = image</span><br><span class="line"></span><br><span class="line">        if self.crop_type == &#x27;rand&#x27;:</span><br><span class="line">            h_off = random.randint(0, h - self.crop_h)</span><br><span class="line">            w_off = random.randint(0, w - self.crop_w)</span><br><span class="line">        else:</span><br><span class="line">            h_off = int((h - self.crop_h) / 2)</span><br><span class="line">            w_off = int((w - self.crop_w) / 2)</span><br><span class="line">        image = image[h_off:h_off + self.crop_h, w_off:w_off + self.crop_w]</span><br><span class="line">        label = label[h_off:h_off + self.crop_h, w_off:w_off + self.crop_w]</span><br><span class="line">        raw_pos_num = np.sum(raw_label == 1)</span><br><span class="line">        pos_num = np.sum(label == 1)</span><br><span class="line">        crop_cnt = 0</span><br><span class="line">        while (pos_num &lt; 0.85 * raw_pos_num and crop_cnt &lt;= 30):</span><br><span class="line">            image = raw_image</span><br><span class="line">            label = raw_label</span><br><span class="line">            if self.crop_type == &#x27;rand&#x27;:</span><br><span class="line">                h_off = random.randint(0, h - self.crop_h)</span><br><span class="line">                w_off = random.randint(0, w - self.crop_w)</span><br><span class="line">            else:</span><br><span class="line">                h_off = int((h - self.crop_h) / 2)</span><br><span class="line">                w_off = int((w - self.crop_w) / 2)</span><br><span class="line">            image = image[h_off:h_off + self.crop_h, w_off:w_off + self.crop_w]</span><br><span class="line">            label = label[h_off:h_off + self.crop_h, w_off:w_off + self.crop_w]</span><br><span class="line">            raw_pos_num = np.sum(raw_label == 1)</span><br><span class="line">            pos_num = np.sum(label == 1)</span><br><span class="line">            crop_cnt += 1</span><br><span class="line">        image = Image.fromarray(image.astype(&#x27;uint8&#x27;))</span><br><span class="line">        label = Image.fromarray(label.astype(&#x27;uint8&#x27;))</span><br><span class="line">        if crop_cnt &gt;= 50:</span><br><span class="line">            # image = cv2.resize(raw_image, (self.size[0], self.size[0]), interpolation=cv2.INTER_LINEAR)</span><br><span class="line">            image = tr_F.resize(raw_image, self.size, interpolation=Image.BILINEAR)</span><br><span class="line">            # label = cv2.resize(raw_label, (self.size[0], self.size[0]), interpolation=cv2.INTER_NEAREST)</span><br><span class="line">            label = tr_F.resize(raw_label, self.size, interpolation=Image.BILINEAR)</span><br><span class="line"></span><br><span class="line">        if image.size != (self.size[0], self.size[0], 3):</span><br><span class="line">            # image = cv2.resize(image, (self.size[0], self.size[0]), interpolation=cv2.INTER_LINEAR)</span><br><span class="line">            image = tr_F.resize(image, self.size, interpolation=Image.BILINEAR)</span><br><span class="line">            # label = cv2.resize(label, (self.size[0], self.size[0]), interpolation=cv2.INTER_NEAREST)</span><br><span class="line">            label = tr_F.resize(label, self.size, interpolation=Image.BILINEAR)</span><br><span class="line"></span><br><span class="line">        sample[&#x27;image&#x27;] = image</span><br><span class="line">        sample[&#x27;semantic_mask&#x27;] = label</span><br><span class="line"></span><br><span class="line">        return sample</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="‚ùìPIL-and-cv2"><a href="#‚ùìPIL-and-cv2" class="headerlink" title="‚ùìPIL and cv2"></a>‚ùìPIL and cv2</h3><p>The image through cv2 can be transformed to <strong>np.array</strong>.</p>
<p>The image through PIL can be transformed to <strong>PIL.image</strong>.</p>
<p>When we do <strong>to_tensor()</strong>, image through cv2 is <strong>Channel number variation</strong>.<br>So when we utilize <code>image = image[:, :, ::-1]</code> or <code>img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</code>, the origin color of cv2 image can be transformed to the color of PIL image.</p>
<p>And the normalization of PIL image is <code>mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]</code>.<br>the normalization of cv2 image without channel variation is <code>mean=[0.485, 0.456, 0.406](*255), std=[0.229, 0.224, 0.225](*255)</code></p>
<p>‚ùódata:</p>
<p>‰ªéÁõ∏ÂêåÊï∞ÊçÆÈõÜÔºåÊ†πÊçÆ‰∏çÂêåÈááÊ†∑ËßÑÂàôÂèñÂá∫‰∏çÂêåÁöÑËÆ≠ÁªÉÊï∞ÊçÆ‰ª•ÂèäÊµãËØïÊï∞ÊçÆÔºåÊïàÊûúÂÆåÂÖ®‰∏çÂêå„ÄÇ</p>
<p>‰πãÂâç‰πüÁåúÊµãÂèØËÉΩÊòØÊï∞ÊçÆÊú¨Ë∫´ÂàÜÁ±ªÁöÑÈóÆÈ¢òÔºå‰ΩÜÊòØÊàëËÆ§‰∏∫Â∞ëÊ†∑Êú¨ÂàÜÂâ≤ÈÉΩÈõÜ‰∏≠‰∫éepisodes‰∏≠ËøõË°åËÆ≠ÁªÉÔºå‰ΩÜÊòØÂêéÈù¢ÂèëÁé∞ÁùÄËøôÁßçÊÉ≥Ê≥ïÊòØÈîôËØØÁöÑ„ÄÇ</p>
<p>Á¨¨‰∏ÄÈò∂ÊÆµÔºö‰ªéÊâÄÊúâÊï∞ÊçÆÈõÜ‰∏≠ÊåëÈÄâÁ¨¶ÂêàË¶ÅÊ±ÇÁöÑÊ†∑Êú¨ÁªÑÊàêepisodes„ÄÇÊúâÈáçÂ§çÊï∞ÊçÆ„ÄÇÂáÜÁ°ÆÂ∫¶ ‚Äì 47%</p>
<p>Á¨¨‰∫åÈò∂ÊÆµÔºö‰ªéÊâÄÊúâÊï∞ÊçÆÈõÜ‰∏≠ÊåëÈÄâÁ¨¶ÂêàË¶ÅÊ±ÇÁöÑÊ†∑Êú¨ÁªÑÊàêepisodes„ÄÇÂéªÈô§ÈáçÂ§çÊï∞ÊçÆ„ÄÇÂáÜÁ°ÆÂ∫¶ ‚Äì 49%</p>
<p>Á¨¨‰∏âÈò∂ÊÆµÔºöÂè™‰ªéËßÑÂÆöÁöÑÊñá‰ª∂voc_sbd_merge_noduplicate.txtÊñá‰ª∂‰∏≠ÊèêÂèñÁõ∏Â∫îÁöÑÊ†∑Êú¨ÁªÑÊàêepisodes„ÄÇÂáÜÁ°ÆÂ∫¶ ‚Äì Ôºà50epochesÔºâ</p>
<p>dataset codeÔºö</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">from torch.utils.data import Dataset</span><br><span class="line">import numpy as np</span><br><span class="line">from PIL import Image</span><br><span class="line">import torch</span><br><span class="line">import os</span><br><span class="line">import time</span><br><span class="line">import logging</span><br><span class="line"></span><br><span class="line">class voc_fewshot(Dataset):</span><br><span class="line">    def __init__(self, base_dir, split, n_ways, n_shots, fold, transformer, to_tensor, n_queries=1):</span><br><span class="line">        # base_path</span><br><span class="line">        self.base_dir = base_dir</span><br><span class="line">        # trainaug</span><br><span class="line">        self.split = split</span><br><span class="line">        # fold</span><br><span class="line">        self.fold = fold</span><br><span class="line">        self.n_ways = n_ways</span><br><span class="line">        # n_shots</span><br><span class="line">        self.n_shots = n_shots</span><br><span class="line">        # transforms</span><br><span class="line">        self.transformer = transformer</span><br><span class="line">        # to_tensor</span><br><span class="line">        self.to_tensor = to_tensor</span><br><span class="line"></span><br><span class="line">        # image path</span><br><span class="line">        self.image_dir = os.path.join(self.base_dir, &quot;JPEGImages&quot;)</span><br><span class="line">        # class segment</span><br><span class="line">        self.class_dir = os.path.join(self.base_dir, &quot;SegmentationClassAug&quot;)</span><br><span class="line">        # instance segment</span><br><span class="line">        self.inst_dir = os.path.join(self.base_dir, &quot;SegmentationObjectAug&quot;)</span><br><span class="line">        # scribble segment</span><br><span class="line">        self.scribble_dir = os.path.join(self.base_dir, &quot;ScribbleAugAuto&quot;)</span><br><span class="line">        # train, val, test, trainaug</span><br><span class="line">        self.id_dir = os.path.join(self.base_dir, &quot;ImageSets&quot;, &quot;Segmentation&quot;)</span><br><span class="line"></span><br><span class="line">        # train or val.txt</span><br><span class="line">        with open(os.path.join(self.id_dir, f&#x27;&#123;self.split&#125;.txt&#x27;), &#x27;r&#x27;) as f:</span><br><span class="line">            self.ids = f.read().splitlines()</span><br><span class="line"></span><br><span class="line">        self.image_label_list = []</span><br><span class="line">        self.sub_class_file_list = &#123;&#125;</span><br><span class="line">        for sub_c in self.fold:</span><br><span class="line">            self.sub_class_file_list[sub_c] = []</span><br><span class="line"></span><br><span class="line">        for temp_id in self.ids:</span><br><span class="line">            temp_id = temp_id.strip()</span><br><span class="line">            temp_path = temp_id.split(&#x27; &#x27;)</span><br><span class="line">            # print(temp_path)</span><br><span class="line">            image_path = os.path.join(self.base_dir, temp_path[0])</span><br><span class="line">            label_path = os.path.join(self.base_dir, temp_path[1])</span><br><span class="line">            item_path = (image_path, label_path)</span><br><span class="line"></span><br><span class="line">            label = np.array(Image.open(label_path))</span><br><span class="line">            label_class = np.unique(label).tolist()</span><br><span class="line"></span><br><span class="line">            if 0 in label_class:</span><br><span class="line">                label_class.remove(0)</span><br><span class="line">            if 255 in label_class:</span><br><span class="line">                label_class.remove(255)</span><br><span class="line"></span><br><span class="line">            new_label_class = []</span><br><span class="line">            for c in label_class:</span><br><span class="line">               if c in self.fold:</span><br><span class="line">                   tmp_label = np.zeros_like(label)</span><br><span class="line">                   target_pix = np.where(label == c)</span><br><span class="line">                   tmp_label[target_pix[0], target_pix[1]] = 1</span><br><span class="line">                   if tmp_label.sum() &gt;= 2 * 32 * 32:</span><br><span class="line">                       new_label_class.append(c)</span><br><span class="line">            # Âè™ÊúâÂØπÂ∫îÁöÑÊ†áÁ≠æÂÄºÂ§ß‰∫é2 * 32 * 32Êâç‰ΩúÊï∞</span><br><span class="line">            label_class = new_label_class</span><br><span class="line"></span><br><span class="line">            # image_label_list -- ÂØπÂ∫îÁöÑqueryÊï∞ÊçÆÈõÜ</span><br><span class="line">            # sub_class_file_list -- ÊåâÈ°∫Â∫èÂ∞ÜËøô‰∫õitemÊîæÂú®ÂØπÂ∫îÊ†áÁ≠æ‰∏≠</span><br><span class="line">            # Â¶ÇÊûúÊúâÁöÑÂõæÁâá‰∏≠ÊâÄÂê´ÊúâÁöÑÊØè‰∏™Ê†áÁ≠æÊï∞ÈáèÈÉΩÂ∞è‰∫é2*32*32ÔºåÈÇ£‰πàËøô‰∏™ÂõæÁâáÂ∞±Ë¢´ËàçÂºÉ</span><br><span class="line">            if len(label_class) &gt; 0:</span><br><span class="line">                self.image_label_list.append(item_path)</span><br><span class="line">                for c in label_class:</span><br><span class="line">                    if c in self.fold:</span><br><span class="line">                        self.sub_class_file_list[c].append(item_path)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, item):</span><br><span class="line">        temp_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        image_path, label_path = self.image_label_list[item]</span><br><span class="line">        image = Image.open(image_path)</span><br><span class="line">        label = Image.open(label_path)</span><br><span class="line">        sample_temp = &#123;</span><br><span class="line">            &#x27;image&#x27;: image,</span><br><span class="line">            &#x27;semantic_mask&#x27;: label</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ori_label = sample_temp[&#x27;semantic_mask&#x27;]</span><br><span class="line"></span><br><span class="line">        sample_temp = self.transformer(sample_temp)</span><br><span class="line"></span><br><span class="line">        # origin image</span><br><span class="line">        image_t = torch.from_numpy(np.array(sample_temp[&#x27;image&#x27;]).transpose(2, 0, 1))</span><br><span class="line">        # origin label</span><br><span class="line">        ori_labels = torch.from_numpy(np.array(ori_label))</span><br><span class="line"></span><br><span class="line">        sample_temp = self.to_tensor(sample_temp)</span><br><span class="line"></span><br><span class="line">        sample_temp[&#x27;ids&#x27;] = image_path.split(&#x27;/&#x27;)[1].split(&#x27;.&#x27;)[0]</span><br><span class="line">        sample_temp[&#x27;image_t&#x27;] = image_t</span><br><span class="line">        sample_temp[&#x27;ori_label&#x27;] = ori_labels</span><br><span class="line"></span><br><span class="line">        ### query ###</span><br><span class="line">        ### support ###</span><br><span class="line">        label1 = np.array(label)</span><br><span class="line">        label_class = np.unique(label1).tolist()</span><br><span class="line"></span><br><span class="line">        if 0 in label_class:</span><br><span class="line">            label_class.remove(0)</span><br><span class="line">        if 255 in label_class:</span><br><span class="line">            label_class.remove(255)</span><br><span class="line">        new_label_class = []</span><br><span class="line">        for c in label_class:</span><br><span class="line">            if c in self.fold:</span><br><span class="line">                new_label_class.append(c)</span><br><span class="line"></span><br><span class="line">        label_class = new_label_class</span><br><span class="line"></span><br><span class="line">        class_chosen = label_class[random.randint(1, len(label_class))-1]</span><br><span class="line"></span><br><span class="line">        support_class_chosen = self.sub_class_file_list[class_chosen]</span><br><span class="line"></span><br><span class="line">        self.support_image_path_list = []</span><br><span class="line">        self.support_label_path_list = []</span><br><span class="line">        self.support_idx_list = []</span><br><span class="line">        for shot in range(self.n_shots):</span><br><span class="line">            support_idx = random.randint(1, len(support_class_chosen))-1</span><br><span class="line">            support_image_path = image_path</span><br><span class="line">            support_label_path = label_path</span><br><span class="line">            while((support_image_path == image_path and support_label_path == label_path) or support_idx in self.support_idx_list):</span><br><span class="line">                support_idx = random.randint(1, len(support_class_chosen)) - 1</span><br><span class="line">                support_image_path, support_label_path = support_class_chosen[support_idx]</span><br><span class="line">            self.support_idx_list.append(support_idx)</span><br><span class="line">            self.support_image_path_list.append(support_image_path)</span><br><span class="line">            self.support_label_path_list.append(support_label_path)</span><br><span class="line"></span><br><span class="line">        for shot in range(self.n_shots):</span><br><span class="line">            s_temp_image_path = self.support_image_path_list[shot]</span><br><span class="line">            s_temp_label_path = self.support_label_path_list[shot]</span><br><span class="line">            support_image = Image.open(s_temp_image_path)</span><br><span class="line">            support_label = Image.open(s_temp_label_path)</span><br><span class="line">            support_sample_temp = &#123;&#x27;image&#x27;: support_image,</span><br><span class="line">                                   &#x27;semantic_mask&#x27;: support_label&#125;</span><br><span class="line">            support_ori_label = support_sample_temp[&#x27;semantic_mask&#x27;]</span><br><span class="line">            support_sample_temp = self.transformer(support_sample_temp)</span><br><span class="line">            support_image_t = torch.from_numpy(np.array(support_sample_temp[&#x27;image&#x27;]).transpose(2, 0, 1))</span><br><span class="line">            support_ori_label = torch.from_numpy(np.array(support_ori_label))</span><br><span class="line">            support_sample_temp = self.to_tensor(support_sample_temp)</span><br><span class="line">            support_sample_temp[&#x27;ids&#x27;] = s_temp_image_path.split(&#x27;/&#x27;)[1].split(&#x27;.&#x27;)[0]</span><br><span class="line">            support_sample_temp[&#x27;image_t&#x27;] = support_image_t</span><br><span class="line">            support_sample_temp[&#x27;ori_label&#x27;] = support_ori_label</span><br><span class="line"></span><br><span class="line">            if class_chosen in temp_dict.keys():</span><br><span class="line">                temp_dict[class_chosen].append(support_sample_temp)</span><br><span class="line">            else:</span><br><span class="line">                temp_dict[class_chosen] = [support_sample_temp]</span><br><span class="line"></span><br><span class="line">        if class_chosen in temp_dict.keys():</span><br><span class="line">            temp_dict[class_chosen].append(sample_temp)</span><br><span class="line">        else:</span><br><span class="line">            temp_dict[class_chosen] = [sample_temp]</span><br><span class="line"></span><br><span class="line">        class_ids = [temp_values for temp_values in temp_dict.keys()]</span><br><span class="line"></span><br><span class="line">        support_images = [[temp_values[j][&#x27;image&#x27;] for j in range(self.n_shots)] for temp_values in temp_dict.values()]</span><br><span class="line">        support_images_t = [[temp_values[j][&#x27;image_t&#x27;] for j in range(self.n_shots)] for temp_values in</span><br><span class="line">                            temp_dict.values()]</span><br><span class="line">        support_labels = [[temp_values[j][&#x27;semantic_mask&#x27;] for j in range(self.n_shots)] for temp_values in</span><br><span class="line">                          temp_dict.values()]</span><br><span class="line"></span><br><span class="line">        # query</span><br><span class="line">        query_images = [[temp_values[j][&#x27;image&#x27;] for j in range(1, len(temp_values))] for temp_values in</span><br><span class="line">                        temp_dict.values()]</span><br><span class="line">        query_images = [ele for ele in query_images if ele != []]</span><br><span class="line">        query_images_t = [[temp_values[j][&#x27;image_t&#x27;] for j in range(1, len(temp_values))] for temp_values in</span><br><span class="line">                          temp_dict.values()]</span><br><span class="line">        query_images_t = [ele for ele in query_images_t if ele != []]</span><br><span class="line">        query_labels = [[temp_values[j][&#x27;semantic_mask&#x27;] for j in range(1, len(temp_values))] for temp_values in</span><br><span class="line">                        temp_dict.values()]</span><br><span class="line">        query_labels = [ele for ele in query_labels if ele != []][0]</span><br><span class="line"></span><br><span class="line">        query_labels_ori = [[temp_values[j][&#x27;ori_label&#x27;] for j in range(1, len(temp_values))] for temp_values in</span><br><span class="line">                            temp_dict.values()]</span><br><span class="line">        query_labels_ori = [ele for ele in query_labels_ori if ele != []][0]</span><br><span class="line"></span><br><span class="line">        query_cls_idx = [sorted([0, ] + [class_ids.index(x) + 1</span><br><span class="line">                                         for x in set(np.unique(query_label)) &amp; set(class_ids)])</span><br><span class="line">                         for query_label in query_labels]</span><br><span class="line">        support_mask = [[self.getMask(support_labels[way][shot],</span><br><span class="line">                                      class_ids[way], class_ids)</span><br><span class="line">                         for shot in range(self.n_shots)] for way in range(self.n_ways)]</span><br><span class="line"></span><br><span class="line">        # --- given 0, 1, 255</span><br><span class="line">        query_labels_tmp = [torch.zeros_like(x) for x in query_labels]</span><br><span class="line">        for i, query_label_tmp in enumerate(query_labels_tmp):</span><br><span class="line">            query_label_tmp[query_labels[i] == 255] = 255</span><br><span class="line">            for j in range(self.n_ways):</span><br><span class="line">                query_label_tmp[query_labels[i] == class_ids[j]] = j + 1</span><br><span class="line"></span><br><span class="line">        query_labels_tmp_ori = [torch.zeros_like(x) for x in query_labels_ori]</span><br><span class="line">        for i, query_label_tmp_ori in enumerate(query_labels_tmp_ori):</span><br><span class="line">            query_label_tmp_ori[query_labels_ori[i] == 255] = 255</span><br><span class="line">            for j in range(self.n_ways):</span><br><span class="line">                query_label_tmp_ori[query_labels_ori[i] == class_ids[j]] = j + 1</span><br><span class="line"></span><br><span class="line">        query_masks = [[torch.where(query_label == 0,</span><br><span class="line">                                    torch.ones_like(query_label),</span><br><span class="line">                                    torch.zeros_like(query_label))[None, ...], ]</span><br><span class="line">                       for query_label in query_labels]</span><br><span class="line"></span><br><span class="line">        for i, query_label in enumerate(query_labels):</span><br><span class="line">            for idx in query_cls_idx[i][1:]:</span><br><span class="line">                mask = torch.where(query_label == class_ids[idx - 1],</span><br><span class="line">                                   torch.ones_like(query_label),</span><br><span class="line">                                   torch.zeros_like(query_label))[None, ...]</span><br><span class="line">                query_masks[i].append(mask)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        return &#123;&#x27;class_ids&#x27;: class_ids,</span><br><span class="line"></span><br><span class="line">                &#x27;support_images_t&#x27;: support_images_t,</span><br><span class="line">                &#x27;support_images&#x27;: support_images,</span><br><span class="line">                &#x27;support_mask&#x27;: support_mask,</span><br><span class="line"></span><br><span class="line">                &#x27;query_images_t&#x27;: query_images_t,</span><br><span class="line">                &#x27;query_images&#x27;: query_images,</span><br><span class="line">                &#x27;query_labels&#x27;: query_labels_tmp,</span><br><span class="line">                &#x27;query_masks&#x27;: query_masks,</span><br><span class="line">                &#x27;query_cls_idx&#x27;: query_cls_idx,</span><br><span class="line">                &#x27;query_labels_ori&#x27;: query_labels_tmp_ori,</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">    def load_image(self):</span><br><span class="line">        all_dict = &#123;&#125;</span><br><span class="line">        for label, id in self.subset.items():</span><br><span class="line">            for ids in id:</span><br><span class="line">                if label in all_dict.keys():</span><br><span class="line">                    all_dict[label].append(ids)</span><br><span class="line">                else:</span><br><span class="line">                    all_dict[label] = [ids]</span><br><span class="line">        return all_dict</span><br><span class="line"></span><br><span class="line">    def sub_fold_set(self):</span><br><span class="line">        # random select classes in fold</span><br><span class="line">        self.fold = list(self.fold)</span><br><span class="line">        classes1 = np.random.choice(self.fold, size=self.n_ways, replace=False)</span><br><span class="line"></span><br><span class="line">        for label in classes1:</span><br><span class="line">            if label in self.selected_classes and len(self.class_item[label]) &lt; (self.n_shots + 1):</span><br><span class="line">                # print(label)</span><br><span class="line">                self.fold.remove(label)</span><br><span class="line">                classes1 = np.random.choice(self.fold, size=self.n_ways, replace=False)</span><br><span class="line"></span><br><span class="line">        for label in classes1:</span><br><span class="line">            if label not in self.selected_classes:</span><br><span class="line">                self.selected_classes.append(label)</span><br><span class="line">                sublabel = []</span><br><span class="line">                with open(os.path.join(self.id_dir, self.split, &#x27;class&#123;&#125;.txt&#x27;.format(label)), &#x27;r&#x27;) as f:</span><br><span class="line">                    sublabel.append(f.read().splitlines())</span><br><span class="line">                self.class_item[label] = sublabel[0]</span><br><span class="line">        cnt_query = np.bincount(random.choices(population=range(self.n_ways), k=self.n_queries), minlength=self.n_ways)</span><br><span class="line">        n_elements = [self.n_shots + x for x in cnt_query]</span><br><span class="line"></span><br><span class="line">        extract_id = &#123;&#125;</span><br><span class="line">        # print(self.class_item)</span><br><span class="line">        for item, label in enumerate(classes1):</span><br><span class="line">            # temp = random.choices(class_item[label], k=n_elements[item])</span><br><span class="line">            # print(len(self.class_item[label]))</span><br><span class="line">            temp = np.random.choice(self.class_item[label], size=n_elements[item], replace=False)</span><br><span class="line">            extract_id[label] = temp</span><br><span class="line"></span><br><span class="line">            for t_temp in temp:</span><br><span class="line">                self.class_item[label].remove(t_temp)</span><br><span class="line"></span><br><span class="line">        return extract_id</span><br><span class="line"></span><br><span class="line">    def getMask(self, label, class_id, class_ids):</span><br><span class="line">        # Â±û‰∫éËØ•Á±ªÂà´ÁöÑÂÉèÁ¥†ËÆæÁΩÆ‰∏∫1</span><br><span class="line">        fg_mask = torch.where(label == class_id, torch.ones_like(label), torch.zeros_like(label))</span><br><span class="line">        bg_mask = torch.where(label != class_id, torch.ones_like(label), torch.zeros_like(label))</span><br><span class="line">        # Âè™Ë¶ÅÊ†áÁ≠æÊúâepisode‰∏≠ÁöÑÁ±ªÂà´ÔºåÂ∞±ËÆæÁΩÆ‰∏∫1</span><br><span class="line">        for class_id in class_ids:</span><br><span class="line">            bg_mask[label == class_id] = 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        return &#123;&#x27;fg_mask&#x27;: fg_mask,</span><br><span class="line">                &#x27;bg_mask&#x27;: bg_mask, &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.image_label_list)</span><br></pre></td></tr></table></figure>

<p>ÊúÄÁªà,Ê†πÊçÆvoc_sbd_merge_noduplicate.txtËÆ≠ÁªÉÂá∫Êù•ÁöÑÂáÜÁ°ÆÂ∫¶ÊòØ54.74%„ÄÇ<br>ÊâÄ‰ª•ÔºåÂæóÂá∫ÁªìËÆ∫Ôºö</p>
<p>trainÔºövoc_sbd_merge_noduplicate.txt</p>
<p>valÔºöval.txt</p>
<p>Âú®ÊµãËØïÈò∂ÊÆµÔºåÊàë‰ª¨ÂèëÁé∞Âä†ËΩΩÊ®°ÂûãÂá∫ÈîôÔºåÂéüÂõ†ÊòØÊØè‰∏™ÂèÇÊï∞ÂêçÈÉΩÂ¢ûÂä†‰∫Ü‰∏Ä‰∏™‚Äômodule.‚Äô„ÄÇËøôÂèØËÉΩÊòØÂõ†‰∏∫Êàë‰ª¨‰ΩøÁî®‰∫ÜÂëΩ‰ª§Ôºö</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.ModuleList</span><br></pre></td></tr></table></figure>

<p>ËøôÈúÄË¶ÅÊàë‰ª¨Â∞Ü‚Äômodule.‚ÄôÂà†Èô§ÔºåÊâÄ‰ª•‰ª£Á†Å‰ªéÔºö</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(torch.load(config.path))</span><br></pre></td></tr></table></figure>
<p>ÂèòÊàêÔºö</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from collections import OrderedDict</span><br><span class="line"></span><br><span class="line">checkpoint = torch.load(config.load_model)[&#x27;state_dict&#x27;]</span><br><span class="line">new_state_dict = OrderedDict()</span><br><span class="line">for k, v in checkpoint.items():</span><br><span class="line">    name = k[7:]</span><br><span class="line">    new_state_dict[name] = v</span><br><span class="line">model.load_state_dict(new_state_dict)</span><br></pre></td></tr></table></figure>

  
    </div> 

    
        <!-- Division Line -->
        <div class="division"></div> 
    

    <div class="post-info-wrapper">
            
                    <!-- Post Info -->
                    <p class="post-date">2023-04-11</p>
                    
                    
                        <p class="post-info-categories">
                            
                        </p>
                    

                    
                        <p class="post-info-tags">
                            
                        </p>
                    
            
    </div>
</article>


    

            </main>

            <!-- 'To Top' Btn-->
            
                <div id="to-top">
    <a href="#top" class="toTop">
        <i class="fa fa-pagelines"></i>
    </a>
</div>
            

            <!-- Footer -->
            
                <footer class="footer-wrapper col-xs-12 col-sm-12">
    <div class="footer-banner-wrapper">
        <p class="footer-banner">Powered by <a target="_blank" rel="noopener" href="https://hexo.io/" title="Hexo">Hexo</a></p>
        <P class="footer-banner">Theme <a target="_blank" rel="noopener" href="https://github.com/Lonezj/hexo-theme-wind" title="Wind">wind</a></P>
    </div>
</footer>
            
        </div>
    </body>
</html>